我们最近在k8s之上开发了一个分布式cron作业调度系统，是一个非常棒的容器编排平台。k8s目前非常流行，而且有很多新功能，其中一个就是工程师们不需要知道应用泡在哪台虚机上。
分布式系统其实很复杂，而管理分布式系统则是运维团队面对的最复杂的问题。在生产环境中引入新软件并学会如何可靠使用时很严肃的问题。例如：为什么学会操作k8s很重要就是一个例子，这里有一个由k8s bug引起一个小时系统瘫痪问题的时候总结。
本博文中，我们会解释为什么要使用k8s，检查如何将k8s整合到现有架构，如何提高k8s集群可靠性，以及我们在k8s之上做的抽象。

##什么是k8s？##
k8s是在集群内调度应用的分布式系统。可以通知k8s运行某个应用的五个实例，k8s则会动态在工作节点上调度起它们。通过自动化调度容器可以增加利用率和节省费用，强大部署能力使得开发者可以细粒度更新代码，安全上下文和网络策略则使得多租户工作流安全运行。
k8s内置许多不同类型的调度策略，可以调度长生命周期的HTTP服务，集群内运行的守护进程集合，每小时运行的cron工作，等等。有需要k8s，如果想了解更多，Kelsy Hightower有很多有趣的专题讨论，例如：k8s for sysadmins和healthz:Stop reverse engineering applications and start monitoring from the inside。在slack社区也有一个非常棒的社区。

##为什么使用k8s？##
每个项目都会从一个业务需求开始。我们的目的是提高已有的基于cron作业系统可靠性和安全性。需求如下：
1. 需要由小团队运维（本项目只有两个全职员工）
2.需要在20台设备内调度大约500个不同作业

我们选择k8s作为基础的原因是：
1.希望采用开源系统
2.k8s有一套内置分布式cron作业调度器，我们不需要重新写一个
3.k8s很活跃，并且乐于接受贡献
4.k8s用Go开发（比较易于学习）。几乎所有bug修复都是有我们团队不专业的Go开发者提交的

如果我们可以顺利操作k8s，我们未来就可以在其上开发（例如，我们现在在k8s之上训练机器学习模型）。以前我们使用Chronos作为cron作业调度系统，但是目前不能满足我们的需求，而且不可维护（活跃度很低）因此我们决定不再采用它。
关于是否采用k8s，最好做到：不要人云亦云；做一个可靠性集群需要很多时间，而也无需求却很不明显。因此要仔细考虑。

##可靠性是什么？##
对于操作服务，可靠性并不如字面那么简单。谈到可靠性，首先需要建立一个SLO（服务级别对象service level objective）。
我们有三种主要目标：
1. 99.99%的cron工作需要在被调度后20分钟之内运行，20分钟是很宽的窗口，但是客户并没有更精确的需求。
2. 作业应该占据99.99%的调度时间片（不被干扰）
3. 迁移到k8s不应引起任何客户端问题

这意味着：
1. k8s API短期故障时可以容忍的（如果出现十分钟的故障，只要五分钟之内恢复就是可以容忍的）
2. 调度bugs（当一个cron作业无法运行）是不可接受的。这是一个很严重的问题。
3. 需要关注pod退出和安全停止方式，以便作业不会频繁被终止。
因为我们需要一个细致的迁移方案。

##创建一个k8s集群##
创建第一个k8s集群最基本方法就是从零开始而不是使用例如kubeadm或者kops之类的工具。我们通过puppet提供配置，这是一个常用的配置管理工具。从零建立有两个原因：能够深度整合k8s到既有架构，深入理解其内部机制。

#从零开始可以帮助我们更好将k8s整合到现存架构#
我们想无缝地整合到日志、认证管理、网络安全、监控、AWS实例管理、部署，数据库代理、内部DNS服务、配置管理等系统中，看起来需要不少精力，但是整体上看比尝试使用kubeadm/kops这些工具来实现目标要容易一些。
因为我们对这些现有系统已经很熟悉了，希望继续在k8s集群中使用它们。例如，安全认证管理一般是一个难点，总是会有这样那样的问题。我们不应该因为采用了k8s而尝试采用一种全新的CA系统。
另外还需要理解某些参数设定对k8s集群的影响。例如，配置认证系统时大量参数需要设置。理解它们对日后查找问题非常重要。

##从小白到高手##
刚开始k8s集成时，团队里没有人用过，如何才能从“小白”到“高手”呢？

#策略0：与其他用户沟通
我们经常会与其他使用过k8s的公司讨论，他们会在不同场合下使用k8s（在物理机、或者google k8s引擎上运行http服务，等等）。与这些有着实际经验的，运行大型或者负责系统的公司沟通后，才会认识到自己使用场景的关键点，建立自己的经验，建立使用的信心，最终下决定。不能只是通过读了这篇博客就认为“好吧，Stirpe成功使用了k8s，因此对我们应该也适用”。
以下是我们跟一些采用k8s集群架构的公司沟通后学到的经验：
重点工作要放在etcd集群可靠性上（etcd是所有k8s集群状态存储的地方），某些k8s功能并不很完善，因此使用alpha版本功能时要很小心。有些公司会以慢一个或几个发行版的方式来采用稳定版本的功能。假设使用hosted k8s系统，例如GKE/AKS/EKS项目,从零开始配置一个高可用k8s集群有大量工作要做，对于这些项目AWS目前还没有一个成熟k8s服务，因此并不适合我们。
另外还需要非常当心overley网络、软件定义网络带来的延迟。当然与其他公司的沟通并不能解决我们自己的问题，但是会给我们更多的启发，并去关注重要的事情。

##策略1：读代码##
我们会依赖k8s的cronjob控制器组件，它目前还是alpha状态，使得我们很担心，尽管在测试系统上使用了，但是如何能够保证在生产上不出问题呢？幸亏cronjob控制器的代买只有区区400行Go语言代码，可以快速读完代码，并且可以看出：
1. cronjob控制器是一个无状态服务（和其它非etcd组件类似）
2. 每十秒钟，控制器调用syncAll服务:go wait.Until(jm.syncAll, 10*time.Second, stopCh)
3. syncAll服务从k8s API中获取所有cronjobs, 检索列表，决定下一个运行那个作业，并启动它。
核心逻辑很简单，但是最重要的是，如果有什么bug，我们应该能够修复。

